{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469bc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Определение констант\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 150 # Максимальная длина предложения (для промптов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f56ce7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device_name = torch.cuda.get_device_name(0)\n",
    "#     print(f\"Доступен GPU: {device_name}\")\n",
    "#     device = torch.device(\"cuda\")\n",
    "# else:\n",
    "#     print(\"GPU недоступен, используется CPU\")\n",
    "#     device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97db844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Класс для словаря\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS и EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# 2. Функции подготовки данных\n",
    "def normalizeString(s):\n",
    "    # Упрощенная нормализация\n",
    "    s = s.lower().strip()\n",
    "    # Убираем теги <s>, </s>, [INST], [/INST]\n",
    "    s = re.sub(r'</?s>', '', s)\n",
    "    s = re.sub(r'\\[/?inst\\]', '', s)\n",
    "    s = s.strip()\n",
    "    # Оставляем базовые символы\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ0-9.!?]+\", r\" \", s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "def read_data(filepath):\n",
    "    pairs = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            text = data.get('text', '')\n",
    "            \n",
    "            # Извлечение INST и ответа\n",
    "            match = re.search(r'\\[INST\\](.*?)\\[/INST\\](.*?)</s>', text, re.DOTALL)\n",
    "            if match:\n",
    "                inst_text = normalizeString(match.group(1))\n",
    "                resp_text = normalizeString(match.group(2))\n",
    "                \n",
    "                # Ограничиваем длину для обучения\n",
    "                if len(inst_text.split(' ')) < MAX_LENGTH and len(resp_text.split(' ')) < MAX_LENGTH:\n",
    "                    pairs.append((inst_text, resp_text))\n",
    "    return pairs\n",
    "\n",
    "def prepareData(filepath):\n",
    "    pairs = read_data(filepath)\n",
    "    print(f\"Загружено {len(pairs)} пар промптов\")\n",
    "    \n",
    "    input_lang = Lang(\"input\")\n",
    "    output_lang = Lang(\"output\")\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Количество слов:\")\n",
    "    print(f\"{input_lang.name}: {input_lang.n_words}\")\n",
    "    print(f\"{output_lang.name}: {output_lang.n_words}\")\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# 3. Функции для тензоров\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word in lang.word2index]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d184db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Определение архитектуры\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout_p), \n",
    "                          bidirectional=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        # Суммируем hidden states из двунаправленной GRU\n",
    "        output = output[:, :, :self.hidden_size] + output[:, :, self.hidden_size:]\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 2 * n_layers, т.к. bidirectional\n",
    "        return torch.zeros(2 * self.n_layers, 1, self.hidden_size, device=device)\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, num_layers=n_layers)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        \n",
    "        # Убедимся, что attn_weights имеет правильную размерность для bmm\n",
    "        # encoder_outputs (seq_len, hidden) -> (1, seq_len, hidden)\n",
    "        # attn_weights (1, max_len) -> (1, 1, max_len)\n",
    "        \n",
    "        # Обрезаем или дополняем attn_weights до seq_len\n",
    "        seq_len = encoder_outputs.size(0)\n",
    "        attn_weights_padded = torch.zeros(1, 1, self.max_length, device=device)\n",
    "        attn_weights_padded[0, 0, :attn_weights.size(1)] = attn_weights\n",
    "        \n",
    "        # Используем фактическую длину seq_len\n",
    "        attn_applied = torch.bmm(attn_weights_padded[:, :, :seq_len],\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.n_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e41245eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Цикл обучения\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # Этот тензор (encoder_outputs) определен корректно\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # ЭТА СТРОКА БЫЛА ЛИШНЕЙ И НЕВЕРНОЙ (удаляем):\n",
    "    # encoder_output_states = torch.zeros(input_length, encoder.hidden_size * 2, device=device)\n",
    "    \n",
    "    # Энкодер\n",
    "    for ei in range(input_length):\n",
    "        # Сохраняем и ВЫХОД (output), и СКРЫТОЕ СОСТОЯНИЕ (hidden)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "        # Сохраняем ВЫХОД (размером 128) в тензор ВЫХОДОВ\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "        # ЭТА СТРОКА БЫЛА НЕВЕРНОЙ (удаляем):\n",
    "        # encoder_output_states[ei] = encoder_hidden[0,0] + encoder_hidden[1,0] # Суммируем\n",
    "        \n",
    "    # Декодер\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    # Используем последний hidden state энкодера (суммированный по направлениям)\n",
    "    decoder_hidden = encoder_hidden[0:decoder.n_layers] + encoder_hidden[decoder.n_layers:]\n",
    "\n",
    "    # Teacher forcing\n",
    "    for di in range(target_length):\n",
    "        # Передаем правильный тензор ВЫХОДОВ (encoder_outputs)\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "# 6. Вспомогательные функции\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "# 7. Запуск обучения\n",
    "def trainIters(encoder, decoder, n_iters, pairs, print_every=1000, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    print_loss_total = 0 \n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Используем случайные пары из данных\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "# 8. Функция инференса\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, normalizeString(sentence))\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_output_states = torch.zeros(input_length, encoder.hidden_size * 2, device=device)\n",
    "        for ei in range(input_length):\n",
    "            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_output_states[ei] = encoder_hidden[0,0] + encoder_hidden[1,0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden[0:decoder.n_layers] + encoder_hidden[decoder.n_layers:]\n",
    "\n",
    "        decoded_words = []\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output_states)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857f536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 300 пар промптов\n",
      "Количество слов:\n",
      "input: 126\n",
      "output: 259\n",
      "1m 5s (- 42m 45s) (500 2%) 0.7129\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = 'prompt_expander_train.jsonl'\n",
    "input_lang, output_lang, pairs = prepareData(DATA_FILE)\n",
    "\n",
    "# Уменьшаем hidden_size для ускорения обучения на CPU\n",
    "hidden_size = 128 \n",
    "n_layers = 1 # 1 слой для Bi-GRU (станет 2 скрытых)\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size, n_layers=n_layers).to(device)\n",
    "# В декодере hidden_size должен соответствовать выходу энкодера (который мы суммируем)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, n_layers=n_layers, dropout_p=0.1).to(device)\n",
    "\n",
    "# n_iters можно увеличить для лучшего качества\n",
    "trainIters(encoder1, attn_decoder1, 20000, pairs, print_every=500) \n",
    "\n",
    "# Сохранение моделей\n",
    "torch.save(encoder1.state_dict(), 'seq2seq_encoder.pth')\n",
    "torch.save(attn_decoder1.state_dict(), 'seq2seq_decoder.pth')\n",
    "torch.save(input_lang, 'input_lang.pth')\n",
    "torch.save(output_lang, 'output_lang.pth')\n",
    "print(\"Модели сохранены.\")\n",
    "\n",
    "# Пример инференса\n",
    "print(\"\\n--- Пример работы ---\")\n",
    "test_prompt = \"Как открыть вклад\"\n",
    "output = evaluate(encoder1, attn_decoder1, test_prompt)\n",
    "print(f\"INPUT: {test_prompt}\")\n",
    "print(f\"OUTPUT: {output}\")\n",
    "\n",
    "test_prompt = \"Как настроить APN\"\n",
    "output = evaluate(encoder1, attn_decoder1, test_prompt)\n",
    "print(f\"INPUT: {test_prompt}\")\n",
    "print(f\"OUTPUT: {output}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
